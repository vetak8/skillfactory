{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-29a43b6ef68e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "from pandas import Series\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# from dataprep.eda import plot, plot_correlation, create_report, plot_missing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler,RobustScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report,recall_score, precision_score\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve,f1_score,plot_precision_recall_curve, plot_roc_curve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "path = '/kaggle/input/sf-dst-scoring/'\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Функция, возвращающая порядковый день в году'''\n",
    "\n",
    "def get_days_count(x):  \n",
    "    day = ((x.month-1) * 30)+x.day\n",
    "    return day\n",
    "\n",
    "'''Функция, возвращающая количество дней между датой заявки и сегодняшним числом'''\n",
    "\n",
    "def get_days_beetwen(x):\n",
    "    curr_date = datetime.today()\n",
    "    count = (curr_date-x).days\n",
    "    return count\n",
    "    \n",
    "\n",
    "'''Функция, возвращающая флаг подачи заявки в выходной день'''\n",
    "\n",
    "def if_weekend(x):\n",
    "    if x.weekday() in [5,6]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def month(x):\n",
    "    month = x.month\n",
    "    return month\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxplot(data,col1,col2,hue=None):\n",
    "    '''Function is called to plot boxplots'''\n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    sns.boxplot(x=col1, y=col2, hue=hue,data=data, palette='mako')\n",
    "    plt.xticks(rotation=45)\n",
    "#     ax.set_title('Boxplot for ' + col1 + 'and' + col2,fontsize=14)\n",
    "    ax.set_title(f'Boxplot for {col1} and {col2}',fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Функция, определяющая флаг наличия поручителя среди людей с образованием 'PGR' и 'ACD'  '''\n",
    "def has_no_garant(edu,grnt):\n",
    "    if edu == 'PGR' or edu == 'ACD':\n",
    "        grnt = 1\n",
    "        return grnt             \n",
    "    else: \n",
    "        grnt = 0\n",
    "        return grnt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "#         self.column = column\n",
    "    \n",
    "    def label_encoder(self,column):\n",
    "        le = LabelEncoder()\n",
    "        self.data[column] = le.fit_transform(self.data[column])\n",
    "        \n",
    "        \n",
    "    def hot_enc(self,column):\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "        aux_df = pd.DataFrame(ohe.fit_transform(self.data[[column]]))\n",
    "        aux_df.columns = ohe.get_feature_names(['hot_encode'])\n",
    "        self.data = pd.concat([self.data, aux_df], axis=1)\n",
    "        return self.data\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_matrix(data, det=True, pltx = 10, plty=10):\n",
    "    X = data.corr()\n",
    "    if det:\n",
    "        \n",
    "        evals,evec = np.linalg.eig(X)\n",
    "        ev_product = np.prod(evals)\n",
    "    \n",
    "        print(f'Rank of Matrix: {np.linalg.matrix_rank(X)}')\n",
    "        print(f'Determinat of matrix: {np.round(ev_product,4)}')\n",
    "        print(f'Shape of matrix: {np.shape(X)}')\n",
    "    \n",
    "    plt.figure(figsize=(pltx,plty))\n",
    "    sns.heatmap(X,vmin=0,vmax=.9,cmap='mako',annot=True,square=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(column,data):\n",
    "    '''Function is called to encode feature'''\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(path+'train.csv')\n",
    "test = pd.read_csv(path+'test.csv')\n",
    "sub = pd.read_csv(path+'sample_submission.csv')\n",
    "\n",
    "# train = pd.read_csv('train.csv')\n",
    "# test = pd.read_csv('test.csv')\n",
    "\n",
    "print(f'Размерность тренировочного датасета: {train.shape}')\n",
    "print(f'Размерность тестового датасета: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим, пересекаются ли данные в тренировочном и тестовом датасетах\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(test.client_id) & set(set(train.client_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (Не пересекаются)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединяем таблицы с добавлением параметра-указателя принадлежности к тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['test'] = 0\n",
    "test['test'] = 1\n",
    "df = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train.drop(['default','test'],axis=1).isnull(), cmap='mako')\n",
    "print(train.isna().mean() * 100) # ВЫражаем пропуски в процентах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описания полей\n",
    "client_id - идентификатор клиента\n",
    "\n",
    "education - уровень образования\n",
    "\n",
    "sex - пол заемщика\n",
    "\n",
    "age - возраст заемщика\n",
    "\n",
    "car - флаг наличия автомобиля\n",
    "\n",
    "car_type - флаг автомобиля иномарки\n",
    "\n",
    "decline_app_cnt - количество отказанных прошлых заявок\n",
    "\n",
    "good_work - флаг наличия “хорошей” работы\n",
    "\n",
    "bki_request_cnt - количество запросов в БКИ\n",
    "\n",
    "home_address - категоризатор домашнего адреса\n",
    "\n",
    "work_address - категоризатор рабочего адреса\n",
    "\n",
    "income - доход заемщика\n",
    "\n",
    "foreign_passport - наличие загранпаспорта\n",
    "\n",
    "sna - связь заемщика с клиентами банка\n",
    "\n",
    "first_time - давность наличия информации о заемщике\n",
    "\n",
    "score_bki - скоринговый балл по данным из БКИ\n",
    "\n",
    "region_rating - рейтинг региона\n",
    "\n",
    "app_date - дата подачи заявки\n",
    "\n",
    "default - флаг дефолта по кредиту\n",
    "\n",
    "\n",
    "####  Вывод: в тренировочной выборке   73799 записей, в тестовой 36349 записей. Имется небольшое количество пропусков в признаке education (0.43% суммарно), которые мы заполним. Данные в тренировочной и тестовой выборках не пересекаются "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas_profiling.ProfileReport(df.drop(['client_id','default','test'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_name = train['education'].value_counts().index.to_list() # Получаем список значений\n",
    "edu_distr = train['education'].value_counts(normalize=True).values # Получаем список вероятностей\n",
    "missing = train['education'].isnull() # Флаги с наличием пропусков\n",
    "train.loc[missing, ['education']] = np.random.choice(\n",
    "    edu_name, size=len(train[missing]), p=edu_distr) # Подставляем значения из списка имен в соответствии в вероятностью встречи имени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['education'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(y='default', data= train, alpha=0.8,palette='mako')\n",
    "total = train.shape[0]\n",
    "\n",
    "for p in ax.patches:\n",
    "    percentage = '{:.1f}%'.format(100 * p.get_width() / total)\n",
    "    x = p.get_x() + p.get_width()\n",
    "    y = p.get_y() + p.get_height() / 2\n",
    "    ax.annotate(percentage,(x,y))\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Имеется дисбаланс классов, попробуем его решить без применения методик по устранению дисбаланса и с ними\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    print('{0:<16} |{1:<10} |{2} '.format(i, train[i].nunique(), train[i].dtypes))\n",
    "    train.dtypes.value_counts(normalize=True).plot(\n",
    "        kind='bar', title='Распределение типов данных')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исходя из кол-ва возможных значений и описания признаков, делим признаки на числовые, категориальные и бинарные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ = ['sex','car','car_type','foreign_passport','good_work']\n",
    "num_ = ['age',  'income', 'score_bki']\n",
    "cat_ = ['decline_app_cnt','bki_request_cnt','education','work_address','home_address', 'sna', 'region_rating','first_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не смотря на то, что признаки  'decline_app_cnt' и 'bki_request_cnt' похожи на числовые с выбросами, мы не будем избавляться от выбросов, но отметим эти признаки как категориальные, т.к. количество запросов в БКИ и количество отказов могут прояснить ситуацию с благополучностью и надежностью потенциального клиента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на них поближе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['decline_app_cnt','bki_request_cnt']:\n",
    "    plt.figure()\n",
    "    sns.boxplot(x=train['default'], y=train[i],palette='mako')\n",
    "    print('\\n\\nРаспределение значений \\'{0}\\'\\n\\n{1}\\n\\n\\n\\n'.format(i,train[\"decline_app_cnt\"].value_counts()))\n",
    "    plt.title(i)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Числовые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем признак с датой и добавим дополнительные фичи "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['app_date'] = pd.to_datetime(train['app_date']) # Преобразуем в datetime\n",
    "train['weekend'] = train['app_date'].apply(lambda x:(if_weekend(x))) # Флаг выходного дня\n",
    "train['days_numb'] = train['app_date'].apply(lambda x:(get_days_count(x))) # Порядковый номер дня в году\n",
    "train['days_beetwen'] = train['app_date'].apply(lambda x:(get_days_beetwen(x))) # Кол- во дней между подачей заявки и сегодняшним числом\n",
    "train['month'] = train['app_date'].apply(lambda x: (month(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('app_date',axis=1) # Удалим столбец app_date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ = bin_ + ['weekend']\n",
    "num_ = num_ + ['days_numb','days_beetwen']\n",
    "cat_ = cat_ + ['month']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_:\n",
    "    plt.figure()\n",
    "    sns.boxplot(x=train['default'], y=train[i],palette='mako')\n",
    "    plt.title(i)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим распределенеие числовых признаков\n",
    "\n",
    "for i in num_:\n",
    "    plt.figure()\n",
    "    sns.distplot(train[i][train[i] > 0].dropna(), kde=False, rug=False)\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''пока не используется'''\n",
    "# def get_blowout(x):\n",
    "#     blowouts = dict.fromkeys(['age', 'income', 'score_bki', 'days_numb', 'days_beetwen'])\n",
    "#     for i in num_:\n",
    "#         Q1 = np.percentile(df[i],25)\n",
    "#         Q3 = np.percentile(df[i],75)\n",
    "#         q_range = Q3 - Q1        \n",
    "#         right = (df[i][df[i] > (Q3+1.5*q_range)]).values\n",
    "#         left = (df[i][df[i] < (Q1-1.5*q_range)]).values\n",
    "#         blowouts.update({i:(set(left),set(right))})\n",
    "#     return display(blowouts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['sex','age']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[num_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Видим, что на графиках имеется выраженный хвост вправо. Прологарифмируем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ЛОГАРИФМИРОВАНИЕ'''\n",
    "train['score_bki'] = train['score_bki'] + 99 # Прибавили число, чтобы избавитья от inf значений \n",
    "for col in num_:\n",
    "    train[col] = np.log(train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in num_:\n",
    "    plt.figure()\n",
    "    sns.distplot(train[i][\n",
    "        train[i] > 0].dropna(), kde=False, rug=False)\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(train[num_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_num = Series(f_classif(train[num_], train['default'])[0], index=num_)\n",
    "imp_num.sort_values(inplace=True)\n",
    "imp_num.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Большую значимость имеет признак score_bki. Признак days_numb и days_beetwen сильно обратно скоррелированы, удалим days_numb т.к его значимость ниже и график расспределения имеет хвост влево "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('days_numb',axis = 1 )\n",
    "num_.remove('days_numb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Бинарные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим графики бинарных признаков от значения 'default' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15, 20])\n",
    "i = 1\n",
    "\n",
    "y, hue = 'proportion', 'default'\n",
    "\n",
    "for k in bin_:\n",
    "    plt.subplot(8, 2, i)\n",
    "    sns.barplot(x=k, y='proportion', hue='default',  data=train[[\n",
    "                k, 'default']].value_counts(normalize=True).rename('proportion').reset_index(),palette='mako')\n",
    "    plt.title('Categorical Feature Name\\n' + k, fontsize=15)\n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "plt.show()    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глядя на барплоты, мы можем отметить, что женщины-заемщики, как правило, несут дефолт несколько чаще, чем мужчины.\n",
    "\n",
    "Заемщики, у которых есть машина, можно считать более надежными. Заемщики, у которых нет машины, как правило, не погашают кредит в два раза чаще, чем те, у кого есть машина.\n",
    "\n",
    "Те заемщики, у которых есть отечественный автомобиль или нет, склонны к дефолту чаще, чем те, у кого есть иномарка. Однако, если мы хотим видеть распределение более четким, нам нужно создать новую категорию в этом столбце: есть отечественная машина, есть иномарка, нет машины.\n",
    "\n",
    "Люди, у которых хорошая работа и загранпаспорт, чаще возвращают ссуды, чем те, у кого плохая работа.\n",
    "\n",
    "Давайте проверим, насколько наши особенности статистически значимы?\n",
    "\n",
    "Для этого давайте закодируем его в двоичные объекты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Preprocessing(train)\n",
    "for col in bin_:\n",
    "    encoder.label_encoder(col)\n",
    "\n",
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_bin = Series(mutual_info_classif(train[bin_], train['default'],\n",
    "                                     discrete_features=True), index=bin_)\n",
    "imp_bin.sort_values(inplace=True)\n",
    "imp_bin.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наиболее важными являются признаки foreign_passport и car_type . Добавленный нами ранее признак флага выходного дня показывает минимальные показатели. Удалим его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('weekend', axis=1)\n",
    "bin_.remove('weekend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(train[bin_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас сильная корреляция между car и car_type. Это можно объяснить тем, что в столбце car указано наличие автомобиля, а в столбце car_type - наличие иномарки, однако отсутствие автомобиля или то, является ли автомобиль отечественным, в car_type не указывается. В разделе проектирования функций мы объединим информацию из этих столбцов в один. Это позволяет уменьшить матрицу характеристик без потери информации.\n",
    "\n",
    "Кроме того, автомобиль немного коррелирует с полом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15, 20])\n",
    "i = 1\n",
    "\n",
    "y, hue = 'proportion', 'default'\n",
    "\n",
    "for k in cat_:\n",
    "    plt.subplot(7, 2, i)\n",
    "    sns.barplot(x=k, y='proportion', hue='default',  data=train[[\n",
    "                k, 'default']].value_counts(normalize=True).rename('proportion').reset_index(),palette='mako')\n",
    "    plt.title('Categorical Feature Name\\n' + k, fontsize=15)\n",
    "    i += 1\n",
    "plt.tight_layout()\n",
    "plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мы видим, что признаки decline_app_cnt и bki_request_cnt имеют очень большой разброс значений. На этапе создания новых признаков мы его уменьшим сгруппировав"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_boxplot(train,'education','region_rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Люди с высоким уровнем образования предпочитают жить в регионе с более высоким уровнем образования.\n",
    "\n",
    "Хорошо, а теперь давайте посмотрим, как распределяются обанкротившиеся заемщики по region_rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_boxplot(train,'default','region_rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем видеть, что клиенты по умолчанию живут в регионах среднего уровня. Чем выше рейтинг города, тем меньше вероятность дефолта. Это должно быть хорошее представление для модели.\n",
    "\n",
    "Интересно, можем ли мы наблюдать какие-то связи между уровнем образования и связью заемщиков с другими клиентами банка? Посмотрим на это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_boxplot(train,'education','sna',hue='default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Связи с клиентами банка имеют люди, в основном с низким уровнем образования. Возможно это можно объяснить тем, что люди с низким образованием работают в больших коллективах (заводы, фабрики) и обмен информации лучше или людям с высоким образованием не нужны поручители. Дефолтных клиентов также больше именно в этих категориях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['has_no_guarantor'] = 0\n",
    "train['has_no_guarantor'] = train[['education','has_no_guarantor']].apply(lambda x:has_no_garant(*x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ = bin_ + ['has_no_guarantor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_:\n",
    "    pre_processing(col,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cat = pd.Series(mutual_info_classif(train[cat_], train['default'], \n",
    "                                     discrete_features=True), index=[cat_])\n",
    "imp_cat.sort_values(inplace=True)\n",
    "imp_cat.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(train[cat_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас довольно сильная корреляция между sna и first_time. Кроме того, эти два столбца имеют наибольшее значение для целевой переменной. Можно предположить, что эти две особенности можно объяснить следующим образом: этот человек давно является клиентом банка и, как следствие, приобрел связи с другими клиентами (возможно, поручителями). Признак меяца имеет статистическое значение. Как-то месяц соотносится с work_address\n",
    "\n",
    "Домашний и рабочий адреса также коррелировали. Нам нужно подумать, что мы можем сделать с этими признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим полную матрицу корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix(train.drop(['default','test'],axis=1),det=False,pltx=20,plty=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим полную корреляцию признака client_id и month (порядковый номер дня в году). Это указывает на определенную систему присвоения номера клиента. Скорее всего, эти знаки дадут нам что-нибудь полезное.\n",
    "\n",
    "car_type коррелирует с доходом. Это можно объяснить предположением, что если у заемщика больше доходов, то у него лучше машина, и наоборот.\n",
    "\n",
    "sna имеет довольно сильную корреляцию с foreign_passport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Выводы\n",
    "\n",
    "**Бинарные:**\n",
    "\n",
    "Автомобиль и car_type сильно коррелированы.\n",
    "\n",
    "В столбце car указано наличие автомобиля, а в столбце car_type - наличие иномарки. Объедините их дальше\n",
    "\n",
    "Количество дефолтных заемщиков мужского и женского пола практически одинаково. Однако женщины чаще ссужают деньги.\n",
    "\n",
    "**Категориальные:**\n",
    "\n",
    "Люди с низким уровнем образования не возвращают кредиты чаще, чем люди с высоким уровнем образования.\n",
    "\n",
    "Больше отношений заемщика с другими клиентами - больше просроченных платежей. Признак **'has no guarantors'**, может быть добавлен людям с высоким уровнем образования.\n",
    "\n",
    "Люди с высоким уровнем образования предпочитают жить в регионе с более высоким уровнем образования.\n",
    "\n",
    "Чем выше рейтинг города, тем меньше вероятность дефолта\n",
    "\n",
    "Корреляция между **'sna'** и **'first_time'**, **'home_address'** и **'work_address'**.\n",
    "\n",
    "**Числовые:**\n",
    "\n",
    "**'score_bki'** имеет распределение близкое к нормальному. Это уже масштабируется ЗППП (скорее всего)\n",
    "\n",
    "У данных есть выбросы. Тем не менее, лучше некоторые функции преобразовать в категориальный тип.\n",
    "\n",
    "Нет сильной корреляции между функциями\n",
    "\n",
    "Car_type коррелирует с доходом\n",
    "\n",
    "Sna имеет довольно сильную корреляцию с foreign_passport\n",
    "\n",
    "**Статистически наиболее значимые:**\n",
    "\n",
    "'foreign_passport'\n",
    "\n",
    "'car_type'\n",
    "\n",
    "'sna'\n",
    "\n",
    "'first_time'\n",
    "\n",
    "'region_rating'\n",
    "\n",
    "'Score_bki'\n",
    "\n",
    "'decline_app_cnt'\n",
    "\n",
    "Поскольку у нас нет очевидной корреляции и связи между признаками, лучше использовать модели descicion tree или logistic regressions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# car & car_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.drop('client_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_name = df['education'].value_counts().index.to_list() # Получаем список значений\n",
    "edu_distr = df['education'].value_counts(normalize=True).values # Получаем список вероятностей\n",
    "missing = df['education'].isnull() # Флаги с наличием пропусков\n",
    "df.loc[missing, ['education']] = np.random.choice(\n",
    "    edu_name, size=len(df[missing]), p=edu_distr) # Подставляем значения из списка имен в соответствии в вероятностью встречи имени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Preprocessing(df)\n",
    "for i in list(['sex','car','car_type','foreign_passport', 'good_work']):\n",
    "    encoder.label_encoder(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['car_comb'] = df['car'] + df['car_type']\n",
    "df = df.drop(['car','car_type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_cat(age):\n",
    "    if age <= 28:\n",
    "        cat_age = 'young'\n",
    "        return cat_age             \n",
    "    if 28 < age <= 35:\n",
    "        cat_age = 'semi-man'\n",
    "        return cat_age\n",
    "    if 35 < age <= 50:\n",
    "        cat_age = 'midle'\n",
    "        return cat_age\n",
    "    if age > 50:\n",
    "        cat_age = 'old'\n",
    "        return cat_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_cat'] = 0\n",
    "df['age_cat'] = df['age'].apply(lambda x:age_to_cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['age_cat'],palette='mako')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decline_app_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='decline_app_cnt', y='proportion', hue='default',  data=train[[\n",
    "                'decline_app_cnt', 'default']].value_counts(normalize=True).rename('proportion').reset_index(),palette='mako')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разделим на группы:\n",
    "1. 0\n",
    "2. 1\n",
    "3. 3\n",
    "4. более или равно 4\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['decline_cat'] = df['decline_app_cnt'].apply(lambda x: 4 if x >= 4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('decline_app_cnt',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bki_request_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='bki_request_cnt', y='proportion', hue='default',  data=train[[\n",
    "                'bki_request_cnt', 'default']].value_counts(normalize=True).rename('proportion').reset_index(),palette='mako')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разделим на группы:\n",
    "1. 0\n",
    "2. 1\n",
    "3. 3\n",
    "4. 4\n",
    "5. 5\n",
    "6. 6\n",
    "7. более или равно 7\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bki_request_cat'] = df['bki_request_cnt'].apply(lambda x: 7 if x >= 7 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('bki_request_cnt',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# home_address & work_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data = df[['work_address','home_address']].values\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(scaled_data)\n",
    "pca_data = pca.transform(scaled_data)\n",
    "df['pca_address'] = pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['home_address','work_address'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# app_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['app_date'] = pd.to_datetime(\n",
    "    df['app_date'])  # Преобразуем в datetime\n",
    "\n",
    "df['days_beetwen'] = df['app_date'].apply(\n",
    "    lambda x: (get_days_beetwen(x)\n",
    "               ))  # Кол- во дней между подачей заявки и сегодняшним числом\n",
    "df['month'] = df['app_date'].apply(lambda x: (month(x)))\n",
    "df = df.drop('app_date',axis=1) # Удалим столбец app_date "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# has_no_guarantor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_no_guarantor'] = 0\n",
    "df['has_no_guarantor'] = df[['education','has_no_guarantor']].apply(lambda x:has_no_garant(*x),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pca_address'] = df['pca_address'] + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pca_address'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Делаем fit_transform для категориальных тренировочной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_encode_cat = ['education','age_cat']\n",
    "for i in to_encode:\n",
    "    pre_processing(i,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_encode_bin = ['sex', 'foreign_passport', 'good_work', 'has_no_guarantor']\n",
    "for i in to_encode:\n",
    "    pre_processing(i,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_train= Preprocessing(df[df['test']==0])\n",
    "cols_to_hot = ['education','region_rating','sna','first_time','car_comb','age_cat','decline_cat','bki_request_cat', 'month']\n",
    "for col in cols_to_hot:\n",
    "    df_train_hotted = encoder_train.hot_enc(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_test= Preprocessing(df[df['test']==1])\n",
    "cols_to_hot = ['education','region_rating','sna','first_time','car_comb','age_cat','decline_cat','bki_request_cat', 'month']\n",
    "for col in cols_to_hot:\n",
    "    df_test_hotted = encoder_test.hot_enc(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pca_address'] = df['pca_address'] + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ЛОГАРИФМИРОВАНИЕ'''\n",
    "to_log = ['age', 'income', 'days_beetwen','pca_address']\n",
    "df['pca_address'] = df['pca_address']\n",
    "for col in to_log:\n",
    "    df[col] = np.log(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scal = ['age', 'income', 'days_beetwen','pca_address']\n",
    "scaler_num = RobustScaler()\n",
    "df_train_scaled = scaler_num.fit_transform(df_train_hotted[to_scal].values)\n",
    "df_test_scaled = scaler_num.transform(df_test_hotted[to_scal].values)\n",
    "\n",
    "df_train_hotted = df_train_hotted.drop(to_scal,axis=1)\n",
    "df_test_hotted = df_test_hotted.drop(to_scal,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_hotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_hotted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_hotted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([df_train_scaled,df_train_hotted.drop(['default','test'],axis=1).values ])\n",
    "y = df_train_hotted[['default']]\n",
    "X_valid = np.hstack([df_test_scaled,df_test_hotted.drop(['default','test'],axis=1).values ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,shuffle=False,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.DataFrame(columns={'ROC-AUG'}, data=[0])\n",
    "\n",
    "df_report['ROC-AUG'] = roc_auc_score(y_test, y_pred_proba)\n",
    "df_report['PR-AUC'] = precision_score(y_test,y_pred)\n",
    "df_report['F1'] = f1_score(y_test,y_pred)\n",
    "df_report['precision_0'] = precision_score(y_test,y_pred,pos_label=0)\n",
    "df_report['recall_0'] = recall_score(y_test,y_pred,pos_label=0)\n",
    "df_report['precision_1'] = precision_score(y_test,y_pred,pos_label=1)\n",
    "df_report['recall_1'] = recall_score(y_test,y_pred,pos_label=1)\n",
    "\n",
    "df_report.index = ['LogisticRegression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13,5))\n",
    "\n",
    "plot_precision_recall_curve(model, X_test, y_test,ax=ax1)\n",
    "plot_roc_curve(model, X_test, y_test, ax=ax2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PR-REC AUC очень низкий, что говорит о том, что алгоритм пока не способен как-либо различать классы, больше всего он присваивает объектам класс 0, попробуем подобрать наилучшие параметры, а также сделаем стратификацию, которая часто применяется при дbбалансе классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "model_skf = LogisticRegression(class_weight='balanced')\n",
    "skf = StratifiedShuffleSplit(n_splits=5, random_state=10)\n",
    "\n",
    "param = {'C':np.linspace(0.001, 10, 10), 'penalty': ['l1','l2']}\n",
    "\n",
    "# refit - по умолчанию, в предикте уже используем лучшую модель\n",
    "clf_model = GridSearchCV(\n",
    "    model_skf, param, scoring='roc_auc', refit=True, cv=skf)\n",
    "clf_model.fit(X_train,y_train)\n",
    "\n",
    "print('Best roc_auc: {:.4}, with best C: {}'.format(clf_model.best_score_, clf_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для возвращения таблицы с метриками\n",
    "def get_scores(report_df, model, X_test, y_test, name):       \n",
    "    \n",
    "    report = pd.DataFrame(columns={'ROC-AUG'}, data=[0])\n",
    "    report['ROC-AUG'] = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    report['PR-AUC'] = precision_score(y_test,model.predict(X_test))\n",
    "    report['F1'] = f1_score(y_test,model.predict(X_test)) \n",
    "    report['precision_0'] = precision_score(y_test,model.predict(X_test),pos_label=0)\n",
    "    report['recall_0'] = recall_score(y_test,model.predict(X_test),pos_label=0)\n",
    "    report['precision_1'] = precision_score(y_test,model.predict(X_test),pos_label=1)\n",
    "    report['recall_1'] = recall_score(y_test,model.predict(X_test),pos_label=1)\n",
    "\n",
    "    report.index = [name]\n",
    "    report_df = report_df.append(report)\n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = get_scores(df_report,clf_model, X_test,y_test, 'LogisticRegression_skf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13,5))\n",
    "\n",
    "plot_precision_recall_curve(clf_model, X_test, y_test,ax=ax1)\n",
    "plot_roc_curve(clf_model, X_test, y_test, ax=ax2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Видим, что в классе 0 поднялась точность и упала полнота, в кассе 1 упала точность и заметно поднялась полнота. В целом подросла f1, но большой разницы при балансировке классов не видно с учетом поиска лучших параметров и статифицированной выборки для обучения.**\n",
    "\n",
    "**Добавим объектов недостоющего класса**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy=1.0)\n",
    "X_over, y_over = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "model_skf = LogisticRegression()\n",
    "skf = StratifiedShuffleSplit(n_splits=5, random_state=10)\n",
    "\n",
    "param = {'C':np.linspace(0.001, 10, 10), 'penalty': ['l1','l2']}\n",
    "\n",
    "# refit - по умолчанию, в предикте уже используем лучшую модель\n",
    "clf_model_over = GridSearchCV(\n",
    "    model_skf, param, scoring='roc_auc', refit=True, cv=skf, verbose =1)\n",
    "clf_model_over.fit(X_over,y_over)\n",
    "\n",
    "print('Best roc_auc: {:.4}, with best C: {}'.format(clf_model.best_score_, clf_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = get_scores(df_report,clf_model_over, X_test,y_test, 'LogisticRegression_skf_imb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13,5))\n",
    "\n",
    "plot_precision_recall_curve(clf_model_over, X_test, y_test,ax=ax1)\n",
    "plot_roc_curve(clf_model_over, X_test, y_test, ax=ax2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После использоания oversampling методики без параметра балансировки в модели, в целом все значения оценок вернулись на исходные значения. Заметим, что хорошо работает встроенный параметр class_weight='balanced'.\n",
    "\n",
    "**Возможно себя лучше покажут решающие деревья**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "df_report = get_scores(df_report,rf, X_test,y_test, 'RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13,5))\n",
    "\n",
    "plot_precision_recall_curve(rf, X_test, y_test,ax=ax1)\n",
    "plot_roc_curve(rf, X_test, y_test, ax=ax2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чет поплыли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_valid = model.predict(X_valid)\n",
    "y_pred_proba_valid = model.predict_proba(X_valid)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "rf_skf = RandomForestClassifier(class_weight='balanced')\n",
    "skf = StratifiedShuffleSplit(n_splits=5, random_state=10)\n",
    "\n",
    "param = {'bootstrap':[True],\n",
    "        'max_depth':[10,30],\n",
    "        'n_estimators':[600,1000]}\n",
    "\n",
    "\n",
    "clf_rf = GridSearchCV(\n",
    "    rf_skf, param, scoring='roc_auc', refit=True, cv=skf, verbose =3, n_jobs=-1)\n",
    "clf_rf.fit(X_train,y_train)\n",
    "\n",
    "print('Best roc_auc: {:.4}, with best C: {}'.format(clf_model.best_score_, clf_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = get_scores(df_report,clf_rf, X_test,y_test, 'RandomForestClassifier_skf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13,5))\n",
    "\n",
    "plot_precision_recall_curve(clf_rf, X_test, y_test,ax=ax1)\n",
    "plot_roc_curve(clf_rf, X_test, y_test, ax=ax2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решающие деревья с использованием стратификации и балансировки показали результат немного лучше логистической регрессии с стратификацией. Немного вырос PR-AUC, F1, полнота класса 0 и точность класса 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "rf_skf = RandomForestClassifier()\n",
    "skf = StratifiedShuffleSplit(n_splits=5, random_state=10)\n",
    "\n",
    "param = {'bootstrap':[True],\n",
    "        'max_depth':[10,30],\n",
    "        'n_estimators':[600,1000]}\n",
    "\n",
    "\n",
    "clf_rf_over = GridSearchCV(\n",
    "    rf_skf, param, scoring='roc_auc', refit=True, cv=skf, verbose =3, n_jobs=-1)\n",
    "clf_rf_over.fit(X_over,y_over)\n",
    "\n",
    "print('Best roc_auc: {:.4}, with best C: {}'.format(clf_model.best_score_, clf_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = get_scores(df_report,clf_rf_over, X_test,y_test, 'RandomForestClassifier_skf_over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13,5))\n",
    "\n",
    "plot_precision_recall_curve(clf_rf_over, X_test, y_test,ax=ax1)\n",
    "plot_roc_curve(clf_rf_over, X_test, y_test, ax=ax2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_over.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_test = test['client_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'client_id': id_test, \n",
    "                            'default': clf_rf_over.predict_proba(X_valid)[:, 1]})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
